{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "badaca7f-1fc3-4f9e-9d68-3aa37603447d",
   "metadata": {},
   "source": [
    "自动文摘的目的是通过对原文本进行压缩、提炼，为用户供简明扼要的文字描述。自动文摘是一个信息压缩过程，将输入的一篇或多篇文档内容总结为一段简要描述，该过程不可避免有信息损失，但是要求保留尽可能多的重要信息，自动文摘也是自然语言生成领域中一个重要任务。\n",
    "下面我们以文本摘要任务为例，展示孟子预训练模型在下游任务上微调的流程，整体流程可以分为4部分：\n",
    "\n",
    "- 数据加载\n",
    "- 数据预处理\n",
    "- 模型训练\n",
    "- 模型推理\n",
    "\n",
    "下面我们以中文科学文献数据（CSL）文本摘要数据为例进行演示，数据下载地址：https://github.com/CLUEbenchmark/CLGE\n",
    "\n",
    "1. 数据加载\n",
    "\n",
    "CSL数据以json的形式存储，通过如下方式可以将数据加载进内存。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9318f008-84ce-4d04-886d-a91ca1cb6b15",
   "metadata": {},
   "source": [
    "依赖环境\n",
    "- transformers\n",
    "- py-rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "94f0f96e-5856-47e5-96e4-505a51df983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, TrainingArguments, Trainer\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "878a541b-a822-429b-a2a8-9a0b775ac51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading...: 100%|██████████| 2500/2500 [00:00<00:00, 245407.23it/s]\n",
      "Reading...: 100%|██████████| 500/500 [00:00<00:00, 129166.79it/s]\n"
     ]
    }
   ],
   "source": [
    "def read_json(input_file: str) -> list:\n",
    "    '''\n",
    "    读取json文件，每行是一个json字段\n",
    "\n",
    "    Args:\n",
    "        input_file:文件名\n",
    "\n",
    "    Returns:\n",
    "        lines\n",
    "    '''\n",
    "    with open(input_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    return list(map(json.loads, tqdm(lines, desc='Reading...')))\n",
    "\n",
    "train = read_json(\"csl/v1/train.json\") \n",
    "dev = read_json(\"csl/v1/dev.json\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9f545e-ffbc-43f7-bdfc-204408194c83",
   "metadata": {},
   "source": [
    "下面展示数据集的具体信息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "53e04393-9e66-42dc-b707-b31e1a3789f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小：2500个样本\n",
      "每个训练样本的原始格式如下：\n",
      " {'id': 2, 'title': '一种基于混合模型的实时虚拟人服装动画方法', 'abst': '实时服装动画生成技术能够为三维虚拟角色实时地生成逼真的服装动态效果,在游戏娱乐、虚拟服装设计展示等领域有着广泛的应用前景.其难点在于如何建立服装动画计算模型,在实时计算的前提下获得最佳的服装动画生成效果.在对服装模型与人体模型在运动过程中发生的位置冲突(collision,也称碰撞)进行分析的基础上,研究并提出了一种基于混合模型的实时虚拟人服装动画计算模型.首先,根据服装动画样本数据中服装与人体发生位置冲突的信息,对服装与人体的运动相关性进行分析;在此基础上,提出并实现一种新的混合策略,将具有较好服装动态模拟效果的动力学计算模型与具有较高计算效率的几何变形方法进行混合,建立支持实时计算且效率可动态控制的服装动画计算模型.实验结果表明,该计算模型能够实时地生成具有较好视觉逼真性的服装动画.'}\n"
     ]
    }
   ],
   "source": [
    "print('训练集大小：%d个训练样本'%(len(train)))\n",
    "print('每个训练样本的原始格式如下：\\n',train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cc3d96-7cc3-4a06-97cd-9e59a08d4035",
   "metadata": {},
   "source": [
    "可以看出每条原始数据包含3个字段，分别是id，title，abst，其中id是唯一标识，abst是文本摘要任务的输入，title是文本摘要任务的输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed38e107-447d-4476-90a8-b1ee809c75dd",
   "metadata": {},
   "source": [
    "2. 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4437e1d-85ab-46f3-aa99-eb2e6d1e6447",
   "metadata": {},
   "source": [
    "数据预处理的目的是将原始数据处理为模型可以接受的输入形式，相当于在原始数据和模型输入之间建立管道。\n",
    "模型输入，可接受的字段为input_ids、labels，其中input_ids为输入文本的tokenized表示，可以直接通过transformers提供的Tokenizer进行转换；labels为模型期望输出文本的tokenized表示。\n",
    "通过定义DataCollatorForSeq2Seq数据预处理类，将其传递给data_collator完成上述流程，数据预处理代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "af4bb983-ebaf-4df4-ae42-1892be31bbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"Langboat/mengzi-t5-base\" # huggingface下载模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83eec31-4ee5-471c-82be-752cc89d2c30",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### 加载预训练模型，包括分词器tokenizer和model。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af548e66-c49d-41d9-842b-0958b54183b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mengzi_tokenizer = T5Tokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d43d696d-a974-41dd-a31d-7b8928754d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mengzi_model = T5ForConditionalGeneration.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9290477-3a9c-4264-9566-9f6df5663a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataset:\n",
    "    def __init__(self, data):\n",
    "        self.datas = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datas)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.datas[index]\n",
    "\n",
    "class DataCollatorForSeq2Seq:\n",
    "    def __init__(self, tokenizer, padding: bool = True, max_length: int = 512):\n",
    "        self.tokenizer = tokenizer\n",
    "        #self.model = model\n",
    "        self.padding = padding\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        features = self.collator_fn(batch)\n",
    "        return features\n",
    "\n",
    "\n",
    "    def preprocess(self, item):\n",
    "        source = item[\"abst\"]\n",
    "        target = item[\"title\"]\n",
    "        return source, target\n",
    "\n",
    "    def collator_fn(self, batch):\n",
    "        results = map(self.preprocess, batch)\n",
    "        inputs, targets = zip(*results)\n",
    "\n",
    "        input_tensor = self.tokenizer(inputs,\n",
    "                                      truncation=True,\n",
    "                                      padding=True,\n",
    "                                      max_length=self.max_length,\n",
    "                                      return_tensors=\"pt\",\n",
    "                                      )\n",
    "\n",
    "        target_tensor = self.tokenizer(targets,\n",
    "                                       truncation=True,\n",
    "                                       padding=True,\n",
    "                                       max_length=self.max_length,\n",
    "                                       return_tensors=\"pt\",\n",
    "                                       )\n",
    "\n",
    "        input_tensor[\"labels\"] = target_tensor[\"input_ids\"]\n",
    "\n",
    "        if \"token_type_ids\" in input_tensor:\n",
    "            del input_tensor[\"token_type_ids\"]\n",
    "        return input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e12554a-00dc-4d0a-a874-06711381cd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Seq2SeqDataset(train)\n",
    "devset = Seq2SeqDataset(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b48f1d71-8a04-4386-bc43-c1ac1b7db6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollatorForSeq2Seq(Mengzi_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eccbf5a-8206-4eaf-895f-2f0492c91df2",
   "metadata": {},
   "source": [
    "3. 模型训练\n",
    "\n",
    "训练模型前需要指定模型训练的超参数，包括训练的轮数、学习率和学习率管理策略等等：可以通过实例化TrainingArguments类来，并将其传递给Trainer来传入这些超参数。\n",
    "然后通过huggingface定义的trainer.train()方法来进行训练。\n",
    "训练完成后通过trainer.save_model()方法来保存最佳模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0449453c-f27a-4ab8-944f-f99d61c024eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"test\" # 模型checkpoint的保存目录\n",
    "training_args = TrainingArguments(\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=8,\n",
    "        logging_steps=10,\n",
    "        #fp16=True,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=100,\n",
    "        load_best_model_at_end=True,\n",
    "        learning_rate=1e-5,\n",
    "        #warmup_steps=100,\n",
    "        output_dir=\"test\",\n",
    "        save_total_limit=5,\n",
    "        lr_scheduler_type='constant',\n",
    "        gradient_accumulation_steps=1,\n",
    "        dataloader_num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "351a0034-eda7-4664-a180-1a9ea67beba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarining Arguments ...\n",
      "TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=4,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=100,\n",
      "evaluation_strategy=IntervalStrategy.STEPS,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "greater_is_better=False,\n",
      "group_by_length=False,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=1e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=test/runs/Nov01_11-42-16_JX-ZY-GPU12,\n",
      "logging_first_step=False,\n",
      "logging_steps=10,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.CONSTANT,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=loss,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3,\n",
      "output_dir=test,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=test,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=None,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard', 'wandb'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=test,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=5,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 2500\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 939\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33megyang\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">test</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/egyang/huggingface\" target=\"_blank\">https://wandb.ai/egyang/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/egyang/huggingface/runs/2oyt4ccp\" target=\"_blank\">https://wandb.ai/egyang/huggingface/runs/2oyt4ccp</a><br/>\n",
       "                Run data is saved locally in <code>/nfs/users/yangerguang/chuangxin/summary/wandb/run-20211101_114247-2oyt4ccp</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='939' max='939' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [939/939 04:47, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.781900</td>\n",
       "      <td>1.654125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.669000</td>\n",
       "      <td>1.454569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.399100</td>\n",
       "      <td>1.426801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.294300</td>\n",
       "      <td>1.377249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.362800</td>\n",
       "      <td>1.363519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.497200</td>\n",
       "      <td>1.342906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.297500</td>\n",
       "      <td>1.321924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.294700</td>\n",
       "      <td>1.321687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.111900</td>\n",
       "      <td>1.306872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test/checkpoint-100\n",
      "Configuration saved in test/checkpoint-100/config.json\n",
      "Model weights saved in test/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in test/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in test/checkpoint-100/special_tokens_map.json\n",
      "Copy vocab file to test/checkpoint-100/spiece.model\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test/checkpoint-200\n",
      "Configuration saved in test/checkpoint-200/config.json\n",
      "Model weights saved in test/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in test/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in test/checkpoint-200/special_tokens_map.json\n",
      "Copy vocab file to test/checkpoint-200/spiece.model\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test/checkpoint-300\n",
      "Configuration saved in test/checkpoint-300/config.json\n",
      "Model weights saved in test/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in test/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in test/checkpoint-300/special_tokens_map.json\n",
      "Copy vocab file to test/checkpoint-300/spiece.model\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test/checkpoint-400\n",
      "Configuration saved in test/checkpoint-400/config.json\n",
      "Model weights saved in test/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in test/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in test/checkpoint-400/special_tokens_map.json\n",
      "Copy vocab file to test/checkpoint-400/spiece.model\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test/checkpoint-500\n",
      "Configuration saved in test/checkpoint-500/config.json\n",
      "Model weights saved in test/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in test/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in test/checkpoint-500/special_tokens_map.json\n",
      "Copy vocab file to test/checkpoint-500/spiece.model\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test/checkpoint-600\n",
      "Configuration saved in test/checkpoint-600/config.json\n",
      "Model weights saved in test/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in test/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in test/checkpoint-600/special_tokens_map.json\n",
      "Copy vocab file to test/checkpoint-600/spiece.model\n",
      "Deleting older checkpoint [test/checkpoint-100] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test/checkpoint-700\n",
      "Configuration saved in test/checkpoint-700/config.json\n",
      "Model weights saved in test/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in test/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in test/checkpoint-700/special_tokens_map.json\n",
      "Copy vocab file to test/checkpoint-700/spiece.model\n",
      "Deleting older checkpoint [test/checkpoint-200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test/checkpoint-800\n",
      "Configuration saved in test/checkpoint-800/config.json\n",
      "Model weights saved in test/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in test/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in test/checkpoint-800/special_tokens_map.json\n",
      "Copy vocab file to test/checkpoint-800/spiece.model\n",
      "Deleting older checkpoint [test/checkpoint-300] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test/checkpoint-900\n",
      "Configuration saved in test/checkpoint-900/config.json\n",
      "Model weights saved in test/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in test/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in test/checkpoint-900/special_tokens_map.json\n",
      "Copy vocab file to test/checkpoint-900/spiece.model\n",
      "Deleting older checkpoint [test/checkpoint-400] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from test/checkpoint-900 (score: 1.306871771812439).\n",
      "Saving model checkpoint to test/best\n",
      "Configuration saved in test/best/config.json\n",
      "Model weights saved in test/best/pytorch_model.bin\n",
      "tokenizer config file saved in test/best/tokenizer_config.json\n",
      "Special tokens file saved in test/best/special_tokens_map.json\n",
      "Copy vocab file to test/best/spiece.model\n"
     ]
    }
   ],
   "source": [
    "print('Tarining Arguments ...')\n",
    "print(training_args)\n",
    "\n",
    "trainer = Trainer(\n",
    "    tokenizer=Mengzi_tokenizer,\n",
    "    model=Mengzi_model,\n",
    "    args=training_args,\n",
    "    data_collator=collator,\n",
    "    train_dataset=trainset,\n",
    "    eval_dataset=devset\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(\"test/best\") # 保存最好的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef383301-4332-4092-840e-9899798fa98a",
   "metadata": {},
   "source": [
    "4. 模型推理\n",
    "\n",
    "最佳模型保存在了\"test/best\"位置，我们可以加载最佳模型并利用其进行摘要生成。\n",
    "下面是我们利用模型进行推理的一种实现方式，将希望简化的文本tokenized后传入模型，得到经过tokenizer解码后即可获得摘要后的文本。当然，读者也可以利用自己熟悉的方式进行生成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84d29708-29f3-45e3-9d13-e93d3ab24ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(items):\n",
    "    inputs = []\n",
    "    titles = []\n",
    "    for item in items:\n",
    "        inputs.append(item[\"abst\"])\n",
    "        titles.append(item[\"title\"])\n",
    "    return inputs, titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6140cd7f-a6c7-46dd-a629-1239c370fa73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading...: 100%|██████████| 500/500 [00:00<00:00, 116859.02it/s]\n"
     ]
    }
   ],
   "source": [
    "test = read_json(\"csl/v1/test.json\")\n",
    "inputs, titles = preprocess(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0f06189-1ec3-4b8b-be41-f27bebb5e3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = \"test/best\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(best_model)\n",
    "model = T5ForConditionalGeneration.from_pretrained(best_model).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3a4834d-ae9e-40c9-97f6-373585ece54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sources, batch_size=8):\n",
    "    _model = model.eval() # 将模型转换为预测模式，使模型内容的droput失效。\n",
    "    \n",
    "    kwargs = {\"num_beams\":4}\n",
    "    \n",
    "    outputs = []\n",
    "    for start in tqdm(range(0, len(sources), batch_size)):\n",
    "        batch = sources[start:start+batch_size]\n",
    "        \n",
    "        input_tensor = tokenizer(batch, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).input_ids.cuda()\n",
    "        \n",
    "        outputs.extend(model.generate(input_ids=input_tensor, **kwargs))\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95aafa6d-45e7-4b04-a56a-403ac45529bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:23<00:00,  2.74it/s]\n"
     ]
    }
   ],
   "source": [
    "generations = predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca784168-6500-4390-9e88-5b050f703ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'基于中心网络的实时数据多播应用'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73e3b2e8-b55c-4672-82e9-60a417d8f6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'网络编码在实时战术数据多播中的应用'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc461586-8d0e-42f8-8a95-a514cadafc8a",
   "metadata": {},
   "source": [
    "#### 生成结果的评测\n",
    "\n",
    "采用自动文摘任务上常用的自动评测指标Rouge-1, Rouge-2, Rouge-L对生成文本的质量进行评测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f9e06f0-36c0-412e-8355-dd5257d74088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "rouge = Rouge()\n",
    "\n",
    "def rouge_score(candidate, reference):\n",
    "    text1 = \" \".join(list(candidate))\n",
    "    text2 = \" \".join(list(reference))\n",
    "    score = rouge.get_scores(text1, text2)\n",
    "    print(score)\n",
    "    return score\n",
    "\n",
    "def compute_rouge(preds, refs):\n",
    "    r1=[]\n",
    "    r2=[]\n",
    "    R_L=[]\n",
    "    for pred, ref in zip(preds, refs):\n",
    "        score = rouge_score(pred, ref)\n",
    "        r1.append(scores[0][\"rouge-1\"][\"f\"])\n",
    "        r2.append(scores[0][\"rouge-2\"][\"f\"])\n",
    "        R_L.append(scores[0][\"rouge-l\"][\"f\"])\n",
    "    return sum(r1)/len(r1), sum(r2)/len(r2), sum(R_L)/len(R_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e34b7f4-04c6-4b43-85bf-ac3461be3390",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_1, R_2, R_L = compute_rouge(generations, titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64b1659-0f08-4bbd-b477-9af5febe178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_L"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
